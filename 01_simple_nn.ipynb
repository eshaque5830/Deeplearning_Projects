{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple neural network using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.1.4-cp39-cp39-win_amd64.whl.metadata (18 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from pandas)\n",
      "  Using cached numpy-1.26.3-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aft\\anaconda3\\envs\\tf_env\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aft\\anaconda3\\envs\\tf_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.1.4-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "Using cached numpy-1.26.3-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/502.5 kB 660.6 kB/s eta 0:00:01\n",
      "   -- ------------------------------------ 30.7/502.5 kB 660.6 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 41.0/502.5 kB 281.8 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/502.5 kB 476.3 kB/s eta 0:00:01\n",
      "   -------- ----------------------------- 112.6/502.5 kB 547.6 kB/s eta 0:00:01\n",
      "   -------- ----------------------------- 112.6/502.5 kB 547.6 kB/s eta 0:00:01\n",
      "   --------- ---------------------------- 122.9/502.5 kB 379.3 kB/s eta 0:00:02\n",
      "   ------------- ------------------------ 174.1/502.5 kB 456.4 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 204.8/502.5 kB 479.2 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 225.3/502.5 kB 492.1 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 235.5/502.5 kB 480.3 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 256.0/502.5 kB 449.3 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 286.7/502.5 kB 465.5 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 317.4/502.5 kB 468.3 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 358.4/502.5 kB 506.8 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 389.1/502.5 kB 485.1 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 399.4/502.5 kB 488.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 450.6/502.5 kB 512.6 kB/s eta 0:00:01\n",
      "   -------------------------------------  501.8/502.5 kB 533.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 502.5/502.5 kB 533.9 kB/s eta 0:00:00\n",
      "Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "   ---------------------------------------- 0.0/346.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/346.6 kB 1.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 81.9/346.6 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------- ------------------------ 122.9/346.6 kB 901.1 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 163.8/346.6 kB 984.6 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 163.8/346.6 kB 984.6 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 174.1/346.6 kB 700.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 174.1/346.6 kB 700.2 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 204.8/346.6 kB 567.2 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 225.3/346.6 kB 551.4 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 225.3/346.6 kB 551.4 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 286.7/346.6 kB 571.2 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 327.7/346.6 kB 616.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  337.9/346.6 kB 566.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 346.6/346.6 kB 567.2 kB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.3 pandas-2.1.4 pytz-2023.3.post1 tzdata-2023.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "imagehash 4.3.1 requires pillow, which is not installed.\n",
      "imagehash 4.3.1 requires PyWavelets, which is not installed.\n",
      "imagehash 4.3.1 requires scipy, which is not installed.\n",
      "matplotlib 3.7.3 requires contourpy>=1.0.1, which is not installed.\n",
      "matplotlib 3.7.3 requires cycler>=0.10, which is not installed.\n",
      "matplotlib 3.7.3 requires fonttools>=4.22.0, which is not installed.\n",
      "matplotlib 3.7.3 requires importlib-resources>=3.2.0; python_version < \"3.10\", which is not installed.\n",
      "matplotlib 3.7.3 requires kiwisolver>=1.0.1, which is not installed.\n",
      "matplotlib 3.7.3 requires pillow>=6.2.0, which is not installed.\n",
      "matplotlib 3.7.3 requires pyparsing>=2.3.1, which is not installed.\n",
      "phik 0.12.3 requires joblib>=0.14.1, which is not installed.\n",
      "phik 0.12.3 requires scipy>=1.5.2, which is not installed.\n",
      "statsmodels 0.14.0 requires patsy>=0.5.2, which is not installed.\n",
      "statsmodels 0.14.0 requires scipy!=1.9.2,>=1.4, which is not installed.\n",
      "statsmodels 0.14.0 requires scipy!=1.9.2,>=1.4; sys_platform == \"win32\", which is not installed.\n",
      "visions 0.7.5 requires attrs>=19.3.0, which is not installed.\n",
      "visions 0.7.5 requires multimethod>=1.4, which is not installed.\n",
      "visions 0.7.5 requires networkx>=2.4, which is not installed.\n",
      "visions 0.7.5 requires tangled-up-in-unicode>=0.0.4, which is not installed.\n",
      "wordcloud 1.9.2 requires pillow, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow  as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   sibsp        891 non-null    int64   \n",
      " 4   parch        891 non-null    int64   \n",
      " 5   fare         891 non-null    float64 \n",
      " 6   class        891 non-null    category\n",
      " 7   who          891 non-null    object  \n",
      " 8   adult_male   891 non-null    bool    \n",
      " 9   deck         203 non-null    category\n",
      " 10  embark_town  889 non-null    object  \n",
      " 11  alive        891 non-null    object  \n",
      " 12  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(1), int64(4), object(4)\n",
      "memory usage: 66.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step before to create the Neural network (preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Preprocessing\n",
    "# Dropping rows \"age\" and \"embarked\" values\n",
    "titanic.drop(['age'], axis=1, inplace=True)\n",
    "\n",
    "# Converting categorical variables to dummy variables (encoding)\n",
    "titanic = pd.get_dummies(titanic, columns=['sex', 'embarked', 'class', 'who', 'deck'])\n",
    "\n",
    "# Selecting features and target\n",
    "X = titanic.drop(['survived', 'alive', 'embark_town', 'adult_male', 'alone'], axis=1)\n",
    "y = titanic['survived']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the dataset\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Building the model\n",
    "# Defines the layers of the model\n",
    "input_layer = tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1], ))  # Input layer\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "\n",
    "model = tf.keras.models.Sequential([input_layer, output_layer])\n",
    "\n",
    "# Compile layers into a model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8581\n",
      "Epoch 2/7\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8567\n",
      "Epoch 3/7\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3209 - accuracy: 0.8567\n",
      "Epoch 4/7\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8581\n",
      "Epoch 5/7\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8596\n",
      "Epoch 6/7\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8581\n",
      "Epoch 7/7\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8596\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8212\n",
      "Test accuracy: 0.8212290406227112\n",
      "CPU times: total: 1.3 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=7, batch_size=32, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.8212\n",
      "Test accuracy: 0.8212290406227112\n",
      "Test loss: 0.5307409763336182\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "print(f\"Test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
